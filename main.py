"""
PubMed å¼•ç”¨æ•°æ€¥å¢—ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ  â€” ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ï¼ˆä»•æ§˜æ›¸ã‚»ã‚¯ã‚·ãƒ§ãƒ³11ï¼‰:
  1. config.py ã‹ã‚‰è¨­å®šèª­ã¿è¾¼ã¿
  2. æ—¥æœ¬èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ MeSH ã‚¯ã‚¨ãƒªã«å¤‰æ›
  3. PubMed API ã§å¯¾è±¡æœŸé–“ã® PMID ä¸€è¦§ã‚’å–å¾—
  4. PMID ã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆDOIãƒ»ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«åãƒ»ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆï¼‰ã‚’å–å¾—
  5. OpenCitations COCI ã§å…ˆæœˆã®å¼•ç”¨æ•°å¢—åŠ ã‚’ç®—å‡º
  6. é–¾å€¤è¶…éè«–æ–‡ã‚’ SQLite DB ã«è¨˜éŒ²
  7. æœªé€šçŸ¥ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
  8. Gemini API ã§ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã‚’æ—¥æœ¬èªè¦ç´„
  9. ã‚¸ãƒ£ãƒ¼ãƒŠãƒ« IF ã‚’è¾æ›¸ã‹ã‚‰å–å¾—
  10. ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‚’ç”Ÿæˆã—ã¦ Gmail é€ä¿¡
  11. é€ä¿¡æ¸ˆã¿è«–æ–‡ã® notified ã‚’æ›´æ–°
"""

import argparse
import logging
import sys
from datetime import datetime
from dateutil.relativedelta import relativedelta

import config
from dictionary import get_mesh_query
from pubmed_fetcher import search_pmids, fetch_article_details
from opencitations import get_citation_increase
from gemini_summarizer import summarize_abstract
from database import init_db, insert_alert, get_pending_alerts, mark_as_notified
from alert import send_alert_email

# =========================================================
# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
# =========================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


def _get_detected_month() -> str:
    """å…ˆæœˆã®å¹´æœˆæ–‡å­—åˆ—ï¼ˆYYYY-MMï¼‰ã‚’è¿”ã™ã€‚"""
    now = datetime.now()
    last_month = now - relativedelta(months=1)
    return last_month.strftime("%Y-%m")


def run(dry_run: bool = False) -> None:
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã€‚

    Args:
        dry_run: True ã®å ´åˆã€ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—
    """
    logger.info("=" * 60)
    logger.info("PubMed å¼•ç”¨æ•°æ€¥å¢—ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ  â€” å®Ÿè¡Œé–‹å§‹")
    logger.info("=" * 60)

    if dry_run:
        logger.info("*** ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ ***")

    # ã‚¹ãƒ†ãƒƒãƒ— 1: è¨­å®šèª­ã¿è¾¼ã¿
    logger.info("ã‚¹ãƒ†ãƒƒãƒ— 1: è¨­å®šèª­ã¿è¾¼ã¿")
    fields = config.DEFAULT_FIELDS
    threshold = config.CITATION_THRESHOLD
    logger.info(f"  å¯¾è±¡åˆ†é‡: {fields}")
    logger.info(f"  é–¾å€¤: {threshold}")

    # DBåˆæœŸåŒ–
    init_db()

    # ã‚¹ãƒ†ãƒƒãƒ— 2: MeSH ã‚¯ã‚¨ãƒªå¤‰æ›
    logger.info("ã‚¹ãƒ†ãƒƒãƒ— 2: æ—¥æœ¬èªâ†’MeSH ã‚¯ã‚¨ãƒªå¤‰æ›")
    mesh_queries = []
    for field in fields:
        query = get_mesh_query(field)
        if query:
            mesh_queries.append(query)
            logger.info(f"  '{field}' â†’ '{query}'")

    if not mesh_queries:
        logger.error("æœ‰åŠ¹ãª MeSH ã‚¯ã‚¨ãƒªãŒã‚ã‚Šã¾ã›ã‚“ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        return

    # ã‚¹ãƒ†ãƒƒãƒ— 3: PubMed æ¤œç´¢
    logger.info("ã‚¹ãƒ†ãƒƒãƒ— 3: PubMed API ã§ PMID ä¸€è¦§ã‚’å–å¾—")
    all_pmids = []
    for query in mesh_queries:
        pmids = search_pmids(query)
        all_pmids.extend(pmids)

    # é‡è¤‡é™¤å»
    all_pmids = list(dict.fromkeys(all_pmids))
    logger.info(f"  åˆè¨ˆ PMID æ•°: {len(all_pmids)}")

    if not all_pmids:
        logger.info("å¯¾è±¡ PMID ãŒã‚ã‚Šã¾ã›ã‚“ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        return

    # ã‚¹ãƒ†ãƒƒãƒ— 4: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    logger.info("ã‚¹ãƒ†ãƒƒãƒ— 4: PubMed efetch ã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—")
    articles = fetch_article_details(all_pmids)
    logger.info(f"  å–å¾—ã—ãŸè«–æ–‡æ•°: {len(articles)}")

    # ã‚¹ãƒ†ãƒƒãƒ— 5-6: å¼•ç”¨æ•°å·®åˆ†è¨ˆç®— + DBè¨˜éŒ²
    logger.info("ã‚¹ãƒ†ãƒƒãƒ— 5-6: OpenCitations ã§å¼•ç”¨æ•°å·®åˆ†è¨ˆç®— + DB è¨˜éŒ²")
    detected_month = _get_detected_month()
    logger.info(f"  æ¤œçŸ¥å¯¾è±¡æœˆ: {detected_month}")
    spike_count = 0

    # çµ±è¨ˆã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    stats_no_doi = 0
    stats_api_fail = 0
    stats_zero_citations = 0
    stats_has_citations = 0
    stats_increase_zero = 0
    stats_increase_positive = 0
    all_increases = []

    total = len(articles)
    for idx, article in enumerate(articles, 1):
        doi = article.get("doi")
        if not doi:
            stats_no_doi += 1
            continue

        if idx % 50 == 0:
            logger.info(f"  é€²æ—: {idx}/{total} ä»¶å‡¦ç†æ¸ˆã¿...")

        increase = get_citation_increase(doi)
        if increase is None:
            stats_api_fail += 1
            continue

        all_increases.append(increase)
        if increase == 0:
            stats_increase_zero += 1
        elif increase > 0:
            stats_increase_positive += 1

        if increase > threshold:
            spike_count += 1
            logger.info(
                f"  ğŸ”” å¼•ç”¨æ€¥å¢—æ¤œçŸ¥: PMID={article['pmid']}, "
                f"å¢—åŠ æ•°={increase}, ã‚¿ã‚¤ãƒˆãƒ«={article['title'][:60]}..."
            )
            insert_alert(
                pmid=article["pmid"],
                doi=doi,
                title=article["title"],
                journal=article["journal"],
                published_date=article["published_date"],
                citation_increase=increase,
                detected_month=detected_month,
            )

    # çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›
    logger.info("  === OpenCitations å‡¦ç†çµ±è¨ˆ ===")
    logger.info(f"  ç·è«–æ–‡æ•°:           {total}")
    logger.info(f"  DOI ãªã—:           {stats_no_doi}")
    logger.info(f"  API å¤±æ•—:           {stats_api_fail}")
    logger.info(f"  å¢—åŠ æ•° = 0:         {stats_increase_zero}")
    logger.info(f"  å¢—åŠ æ•° > 0:         {stats_increase_positive}")
    logger.info(f"  é–¾å€¤è¶…é (>{threshold}):    {spike_count}")
    if all_increases:
        logger.info(f"  å¢—åŠ æ•° æœ€å¤§å€¤:      {max(all_increases)}")
        logger.info(f"  å¢—åŠ æ•° Top5:        {sorted(all_increases, reverse=True)[:5]}")

    # ã‚¹ãƒ†ãƒƒãƒ— 7: æœªé€šçŸ¥ãƒ¬ã‚³ãƒ¼ãƒ‰å–å¾—
    logger.info("ã‚¹ãƒ†ãƒƒãƒ— 7: æœªé€šçŸ¥ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å–å¾—")
    pending = get_pending_alerts(detected_month)
    logger.info(f"  æœªé€šçŸ¥ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(pending)}")

    if not pending:
        logger.info("é€šçŸ¥å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        return

    # ã‚¹ãƒ†ãƒƒãƒ— 8: Gemini è¦ç´„
    logger.info("ã‚¹ãƒ†ãƒƒãƒ— 8: Gemini API ã§ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆæ—¥æœ¬èªè¦ç´„")
    for alert_record in pending:
        pmid = alert_record["pmid"]
        # ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã‚’å–å¾—ï¼ˆarticlesã‹ã‚‰æ¤œç´¢ï¼‰
        abstract = None
        for article in articles:
            if article["pmid"] == pmid:
                abstract = article.get("abstract")
                break

        if abstract:
            summary = summarize_abstract(abstract)
        else:
            summary = "ï¼ˆã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆãŒå­˜åœ¨ã—ãªã„ãŸã‚è¦ç´„ã§ãã¾ã›ã‚“ï¼‰"

        alert_record["summary"] = summary
        logger.info(f"  PMID={pmid}: è¦ç´„å®Œäº†")

    # ã‚¹ãƒ†ãƒƒãƒ— 9: IF ã¯ãƒ¡ãƒ¼ãƒ«ç”Ÿæˆæ™‚ã« dictionary.py ã‹ã‚‰è‡ªå‹•å–å¾—

    # ã‚¹ãƒ†ãƒƒãƒ— 10: ãƒ¡ãƒ¼ãƒ«é€ä¿¡
    logger.info("ã‚¹ãƒ†ãƒƒãƒ— 10: ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¡ãƒ¼ãƒ«é€ä¿¡")
    if dry_run:
        logger.info("  [ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³] ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        logger.info("  === ãƒ¡ãƒ¼ãƒ«å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ===")
        for alert_record in pending:
            logger.info(
                f"  ã‚¿ã‚¤ãƒˆãƒ«: {alert_record.get('title', 'N/A')}"
            )
            logger.info(
                f"  å¢—åŠ æ•°: +{alert_record.get('citation_increase', 0)}"
            )
            logger.info(
                f"  è¦ç´„: {alert_record.get('summary', 'N/A')[:100]}..."
            )
            logger.info("  ---")
    else:
        success = send_alert_email(pending)
        if not success:
            logger.error("ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return

    # ã‚¹ãƒ†ãƒƒãƒ— 11: notified æ›´æ–°
    logger.info("ã‚¹ãƒ†ãƒƒãƒ— 11: notified ãƒ•ãƒ©ã‚°ã‚’æ›´æ–°")
    alert_ids = [a["id"] for a in pending]
    if not dry_run:
        mark_as_notified(alert_ids)
        logger.info(f"  {len(alert_ids)} ä»¶ã‚’é€šçŸ¥æ¸ˆã¿ã«æ›´æ–°")
    else:
        logger.info(f"  [ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³] {len(alert_ids)} ä»¶ã®æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—")

    logger.info("=" * 60)
    logger.info("PubMed å¼•ç”¨æ•°æ€¥å¢—ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ  â€” å®Ÿè¡Œå®Œäº†")
    logger.info("=" * 60)


def main():
    parser = argparse.ArgumentParser(
        description="PubMed å¼•ç”¨æ•°æ€¥å¢—ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ "
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ",
    )
    args = parser.parse_args()

    try:
        run(dry_run=args.dry_run)
    except Exception as e:
        logger.exception(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
